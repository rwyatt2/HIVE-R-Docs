---
title: "Phase 3: Test Suite Generation"
sidebar_label: "Phase 3: Test Suite Generation"
---

**

**â±ï¸ Time**: 8-12 hours

**ğŸ’° Budget**: $20-30

**ğŸ¯ Goal**: 70% test coverage using HIVE-R to test itself

**ğŸ¤– AI Workers**: HIVE-R Tester + Builder agents

**ğŸ§ª Step 3.1: Generate Tests for Core Graph Logic**

**Your Instruction** (in Cursor, open src/graph.ts):

  

  

ğŸ¯ META-TASK: Use HIVE-R to test HIVE-R

  

Consult the HIVE-R swarm.

  

CONTEXT:

This is the core LangGraph orchestration logic. It's critical but has zero tests.

  

TASK FOR TESTER AGENT:

Analyze this file and generate comprehensive Vitest test suite covering:

Â  1. Graph construction (nodes added correctly)

Â  2. State updates (messages append correctly)

Â  3. Agent routing (router chooses correct agent)

Â  4. Error handling (what if agent throws error?)

Â  5. Edge cases (empty messages, invalid agent names)

  

TEST REQUIREMENTS:

- Mock all LLM calls (use vitest.mock())

- Test both success and failure paths

- Use fixtures for common test data

- Fast (no real API calls, &lt;1s per test)

- Clear test names (describe what's being tested)

  

TASK FOR BUILDER AGENT:

- Review Tester's proposed tests

- Implement any helper functions needed

- Ensure tests actually compile and run

  

OUTPUT:

- New file: tests/graph.test.ts

- Test fixtures: tests/fixtures/agent-responses.ts

- At least 10 test cases

- 100% coverage of graph.ts critical paths

  

**â¸ï¸ YOUR APPROVAL GATE**:

Review the generated test file:

â˜ Tests are meaningful (not just checking trivial things)

â˜ Mocks look realistic (resembles actual LLM responses)

â˜ Coverage includes error cases (not just happy path)

â˜ Test names are descriptive: "should route to builder agent when user asks for code"

**Run tests**:

  

  

npm test tests/graph.test.ts

  

# Check coverage

npm run test:coverage -- tests/graph.test.ts

# Should show high coverage (80%+) for graph.ts

  

**If tests fail**: Don't debug manually! Ask AI:

  

  

Tests are failing with this error: [paste error]

  

Analyze the failure and fix the tests (not the source code unless there's a real bug).

  

**âœ… Validation**:

â˜ All tests pass

â˜ Coverage >80% for graph.ts

â˜ Tests run fast (&lt;5s total)

â˜ No real API calls made

**ğŸ“Š Log Cost**: ~$0.15 (45K tokens for test generation)

**ğŸ”¨ Step 3.2: Generate Tests for Agent Implementations**

**Your Instruction** (in Cursor):

  

  

Consult the Tester agent.

  

CONTEXT:

We have 13 agent files in src/agents/. Each needs unit tests.

  

TASK:

For EACH agent file (router, builder, security, planner, etc.):

Â  1. Analyze the agent's prompt and tools

Â  2. Generate test cases for expected behaviors

Â  3. Mock the underlying LLM calls

Â  4. Test tool invocations (if agent uses tools)

  

PRIORITIZE THESE AGENTS FIRST:

Â  1. router.ts (most critical)

Â  2. builder.ts (most used)

Â  3. security.ts (high risk)

Â  4. tester.ts (meta: test the tester!)

  

BATCH APPROACH:

- Generate tests for all 4 priority agents in one go

- Use consistent test structure across all

- Share fixtures where possible

  

OUTPUT:

- tests/agents/router.test.ts

- tests/agents/builder.test.ts

- tests/agents/security.test.ts

- tests/agents/tester.test.ts

- Shared fixtures: tests/fixtures/llm-responses.ts

  

**â¸ï¸ YOUR APPROVAL GATE**:

This is a big batch. Review one test file first:

â˜ tests/agents/router.test.ts looks comprehensive

â˜ Mocking strategy makes sense

â˜ Tests cover the agent's key responsibilities

**Approve remaining agents**: "Router tests look good, generate the other 3 with same approach"

**Run tests**:

  

  

npm test tests/agents/

  

# Check which agents have good coverage

npm run test:coverage -- tests/agents/

# Target: 70%+ for each priority agent

  

**âœ… Validation**:

â˜ All 4 priority agents have test files

â˜ Tests pass

â˜ Coverage >70% for router, builder, security

â˜ No real LLM calls (check test run time &lt;10s)

**ğŸ“Š Log Cost**: ~$0.40 (120K tokens - this is the biggest batch)

**ğŸ› ï¸ Step 3.3: Generate Integration Tests**

**Your Instruction** (in Cursor):

  

  

Consult the Tester agent.

  

CONTEXT:

Unit tests are good, but we need integration tests for multi-agent workflows.

  

TASK:

Create integration tests for these user journeys:

Â  1. "Build a simple React app" (Founder â†’ PM â†’ Planner â†’ Builder)

Â  2. "Review this code for security issues" (Security â†’ Reviewer)

Â  3. "Deploy this to production" (SRE â†’ Security â†’ Deployment)

  

TEST REQUIREMENTS:

- Start from user message

- Trace through multiple agent handoffs

- Mock LLM responses for each agent in sequence

- Verify final output matches expectations

- Test that context flows between agents

  

TECHNICAL APPROACH:

- Use real graph.ts (not mocked)

- Mock only the LLM calls

- Fixtures for multi-turn conversations

- Longer tests (30s timeout acceptable)

  

OUTPUT:

- tests/integration/multi-agent-workflows.test.ts

- Detailed fixtures: tests/fixtures/workflows/

- At least 3 complete workflows tested

  

**â¸ï¸ YOUR APPROVAL GATE**:

Integration tests are complex. Review the approach:

â˜ Tests actually invoke multiple agents (not shortcuts)

â˜ Fixtures represent realistic agent responses

â˜ Tests verify handoff logic (agent A â†’ agent B)

â˜ Clear failure messages (which agent failed, why)

**Run tests**:

  

  

npm test tests/integration/

  

# These will be slower (that's OK)

# Should complete in &lt;30s total

  

**If tests are too slow** (>1min): Ask AI to add more aggressive mocking or parallelize tests.

**âœ… Validation**:

â˜ Integration tests pass

â˜ Cover 3 key workflows

â˜ Tests complete in &lt;30s

â˜ Verify agent handoffs work correctly

**ğŸ“Š Log Cost**: ~$0.20 (60K tokens)

**ğŸ” Step 3.4: Add Test Coverage Reporting**

**Your Instruction** (in Cursor, open package.json):

  

  

Consult the Builder agent.

  

TASK:

Add test coverage reporting to our npm scripts.

  

REQUIREMENTS:

- Use Vitest's built-in coverage (c8 or istanbul)

- Generate HTML report (for visual review)

- Generate JSON report (for CI integration)

- Add npm script: "test:coverage"

- Coverage thresholds:

Â  - Statements: 70%

Â  - Branches: 60%

Â  - Functions: 70%

Â  - Lines: 70%

  

OUTPUT:

- Updated package.json with coverage config

- Updated vitest.config.ts with thresholds

- Documentation: docs/development/testing.md

- CI integration (runs in GitHub Actions)

  

**â¸ï¸ YOUR APPROVAL GATE**:

Review the thresholds:

â˜ 70% is achievable (not too low or too high)

â˜ Critical files (graph.ts, agents/*) excluded from low coverage

â˜ HTML report will be gitignored (not committed)

**Run coverage**:

  

  

npm run test:coverage

  

# Opens coverage/index.html in browser

# Review which files have low coverage

  

**If coverage is &lt;70%**: Ask AI to generate more tests for specific files:

  

  

Coverage for src/lib/memory.ts is only 45%. Generate tests to bring it to 70%+.

  

**âœ… Validation**:

â˜ Overall coverage >70%

â˜ HTML report generated

â˜ Coverage badge shows in README (optional)

â˜ CI configured to run coverage

**ğŸ“Š Log Cost**: ~$0.05 (15K tokens)

**ğŸ¤– Step 3.5: Document Testing Strategy**

**Your Instruction** (in Cursor):

  

  

Consult the Tech Writer agent.

  

CONTEXT:

We now have a comprehensive test suite. Document how to use it.

  

TASK:

Create developer documentation covering:

Â  1. How to run tests locally

Â  2. How to run specific test files

Â  3. How to write new tests (with examples)

Â  4. Testing philosophy (unit vs integration)

Â  5. Mocking strategy (when to mock, when to use real code)

Â  6. Coverage requirements (70% for new code)

Â  7. CI integration (tests run on every PR)

Â  8. Troubleshooting common test issues

  

OUTPUT:

- docs/development/testing.md

- Code examples for common test patterns

- Link from main README.md

  

**â¸ï¸ YOUR APPROVAL GATE**:

Read the documentation:

â˜ Clear instructions for beginners

â˜ Code examples are copy-pasteable

â˜ Explains WHY we test (not just HOW)

â˜ Covers troubleshooting

**âœ… Validation**:

â˜ Documentation exists and is thorough

â˜ README links to it

â˜ You understand how to add tests yourself (if needed)

**ğŸ“Š Log Cost**: ~$0.03 (10K tokens)

**âœ… Phase 3 Complete When:**

â˜ Test coverage >70% overall

â˜ All critical files (graph, agents) >80% coverage

â˜ Integration tests for 3 key workflows

â˜ Coverage reporting configured

â˜ Testing documentation complete

â˜ All tests passing on local machine

â˜ Total cost &lt;$30 for Phase 3

**ğŸ’¡ Key Insight**: You can now refactor and add features confidently. Tests catch regressions.

**ğŸ‰ MAJOR MILESTONE**: Your codebase is now tested better than 90% of AI projects.

**