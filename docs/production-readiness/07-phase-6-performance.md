---
title: "Phase 6: Performance Optimization"
sidebar_label: "Phase 6: Performance Optimization"
---

**

**â±ï¸ Time**: 10-12 hours

**ğŸ’° Budget**: $25-30

**ğŸ¯ Goal**: 50% cost reduction, 80% latency reduction (for cached requests)

**ğŸ¤– AI Workers**: HIVE-R Data Analyst + Builder + Planner agents

**âš¡ Step 6.1: Implement Response Caching**

**Your Instruction** (in Cursor):

  

  

Consult the Planner and Builder agents.

  

CONTEXT:

Many user requests are similar or identical. We're calling expensive LLMs unnecessarily.

  

TASK:

Planner: Design caching strategy

Â  - What to cache? (completed agent responses)

Â  - Cache key? (hash of messages + agent + model)

Â  - TTL? (1 hour for code generation, 24h for planning)

Â  - Invalidation? (user can force refresh, or version changes)

Â  - Storage? (Redis for shared cache, or in-memory for dev)

  

Builder: Implement semantic caching

Â  - Use embeddings to find similar queries (cosine similarity >0.95)

Â  - Store: embedding vector, original query, response, metadata

Â  - Check cache before every agent invocation

Â  - Metrics: cache_hit_rate, cache_latency

  

SEMANTIC SEARCH:

- Generate embedding for new query (OpenAI text-embedding-ada-002)

- Vector search in Redis (with RedisSearch) or Qdrant

- If similarity >0.95, return cached response

- If miss, invoke agent and cache result

  

DELIVERABLES:

- Cache strategy doc: docs/architecture/caching.md

- Redis setup in docker-compose

- Semantic cache implementation: src/lib/semantic-cache.ts

- Integration in agent middleware

- Cache management endpoints: /api/admin/cache/clear

  

**â¸ï¸ YOUR APPROVAL GATE**:

Review the caching strategy:

â˜ Similarity threshold (0.95) is reasonable (not too loose)

â˜ TTLs make sense (short for dynamic, long for static)

â˜ Cache doesn't store sensitive data (user IDs anonymized)

â˜ Has manual override (users can bypass cache with flag)

**Setup Redis**:

  

  

# Add to docker-compose.yml

cat >> docker-compose.yml &lt;< 'EOF'

Â  redis:

Â  Â  image: redis/redis-stack:latestÂ  # Includes RedisSearch

Â  Â  ports:

Â  Â  Â  - "6379:6379"

Â  Â  Â  - "8001:8001"Â  # RedisInsight UI

Â  Â  volumes:

Â  Â  Â  - redis-data:/data

EOF

  

docker-compose up -d redis

  

**Test caching**:

  

  

# First request (cache miss)

time curl http://localhost:3000/chat -d '&#123;"messages":[&#123;"role":"user","content":"build a login form"&#125;]&#125;'

# Should take 3-5 seconds

  

# Second identical request (cache hit)

time curl http://localhost:3000/chat -d '&#123;"messages":[&#123;"role":"user","content":"build a login form"&#125;]&#125;'

# Should take &lt;100ms

  

# Similar request (semantic hit)

time curl http://localhost:3000/chat -d '&#123;"messages":[&#123;"role":"user","content":"create a login page"&#125;]&#125;'

# Should also be fast (similar query)

  

# Check metrics

curl http://localhost:3000/metrics | grep cache_hit_rate

# Should show >0.5 (50% hit rate after a few requests)

  

**âœ… Validation**:

â˜ Cache reduces latency by 80%+ for hits

â˜ Semantic search works (similar queries match)

â˜ Cache doesn't serve stale data (TTL works)

â˜ Cache hit rate >30% after 100 requests

**ğŸ’° Cost Savings**: 50% reduction if cache hit rate = 50%

**ğŸ“Š Log Cost**: ~$0.20 (60K tokens)

**ğŸ¯ Step 6.2: Implement Intelligent Model Routing**

**Your Instruction** (in Cursor):

  

  

Consult the Data Analyst and Planner agents.

  

CONTEXT:

We're using expensive models (Claude, GPT-4o) for all tasks. Many tasks could use cheaper models.

  

TASK:

Data Analyst: Analyze task complexity

Â  - Simple tasks (&lt;100 tokens output): GPT-4o-mini ($0.15/MTok)

Â  - Medium tasks (100-500 tokens): GPT-4o ($5/MTok)

Â  - Complex tasks (>500 tokens, code generation): Claude ($3/MTok)

  

Planner: Design routing logic

Â  - Estimate task complexity from prompt (use heuristics or small model)

Â  - Select cheapest model that can handle it

Â  - Track model performance (did cheaper model succeed?)

Â  - Auto-upgrade if cheap model fails repeatedly

  

HEURISTICS:

- "simple question", "what is", "explain" â†’ cheap model

- "build", "implement", "refactor" â†’ expensive model

- "review", "analyze", "compare" â†’ medium model

  

IMPLEMENTATION:

- Model router: src/lib/model-router.ts

- Complexity estimator (rule-based or ML)

- Fallback if cheap model fails

- Metrics: cost_saved_by_routing

  

DELIVERABLES:

- Model routing logic

- Integration in agent invocations

- Performance tracking dashboard

- A/B test results (routed vs always-expensive)

  

**â¸ï¸ YOUR APPROVAL GATE**:

Review the routing heuristics:

â˜ Rules make sense (not too aggressive on downgrading)

â˜ Has safety net (upgrades if cheap model fails)

â˜ Tracks performance (can revert if quality drops)

â˜ Doesn't route security tasks to cheap models

**Test routing**:

  

  

# Simple query (should use cheap model)

curl http://localhost:3000/chat -d '&#123;"messages":[&#123;"role":"user","content":"what is react?"&#125;]&#125;'

# Check logs for: "Model selected: gpt-4o-mini"

  

# Complex query (should use expensive model)

curl http://localhost:3000/chat -d '&#123;"messages":[&#123;"role":"user","content":"build a full authentication system with JWT"&#125;]&#125;'

# Check logs for: "Model selected: claude-3-5-sonnet"

  

# After 100 requests, check savings

curl http://localhost:3000/metrics | grep cost_saved

# Should show significant savings (30-50%)

  

**âœ… Validation**:

â˜ Simple tasks use cheap models

â˜ Complex tasks use expensive models

â˜ Quality doesn't drop (test manually or with eval set)

â˜ Cost savings 30-50%

**ğŸ’° Cost Savings**: Additional 30-40% on top of caching

**ğŸ“Š Log Cost**: ~$0.15 (45K tokens)

**ğŸ—„ï¸ Step 6.3: Optimize Database Queries**

**Your Instruction** (in Cursor):

  

  

Consult the Data Analyst and Builder agents.

  

CONTEXT:

Database queries can be slow, especially as data grows. Optimize now before it becomes a problem.

  

TASK:

Data Analyst: Analyze current queries

Â  - Run EXPLAIN on all queries in src/lib/*.ts

Â  - Identify slow queries (>100ms)

Â  - Recommend indexes

Â  - Check for N+1 query problems

  

Builder: Implement optimizations

Â  - Add missing indexes

Â  - Rewrite slow queries (use JOINs instead of multiple SELECTs)

Â  - Add query result caching (for analytics)

Â  - Use connection pooling

Â  - Consider read replicas if high read load

  

FOCUS AREAS:

1. token_usage table (heavy writes, frequent aggregations)

2. chat_history table (joins with users)

3. agent_state table (if exists)

  

DELIVERABLES:

- Database analysis: docs/architecture/db-optimization.md

- Index creation migration

- Query rewrites (before/after benchmarks)

- Connection pool configuration

- Performance comparison report

  

**â¸ï¸ YOUR APPROVAL GATE**:

Review the proposed indexes:

â˜ Indexes on foreign keys (user_id, session_id)

â˜ Indexes on frequently queried columns (timestamp, agent_name)

â˜ Not over-indexed (too many indexes slow writes)

â˜ Composite indexes for common query patterns

**Run optimization**:

  

  

# Run database migrations

npm run db:migrate

  

# Run benchmark before/after

npm run benchmark:db

  

# Check query performance

sqlite3 data/hive.db &lt;< 'EOF'

EXPLAIN QUERY PLANÂ 

SELECT SUM(cost_usd) FROM token_usageÂ 

WHERE timestamp > datetime('now', '-1 day')Â 

GROUP BY agent_name;

EOF

# Should show "USING INDEX idx_token_usage_timestamp"

  

**âœ… Validation**:

â˜ All slow queries now &lt;50ms

â˜ Indexes used (check EXPLAIN output)

â˜ Write performance not degraded

â˜ Connection pool active (check logs)

**ğŸ“Š Log Cost**: ~$0.10 (30K tokens)

**ğŸ”¥ Step 6.4: Implement Request Rate Limiting**

**Your Instruction** (in Cursor):

  

  

Consult the Security and Builder agents.

  

CONTEXT:

Users (or attackers) could spam our API, causing cost explosions.

  

TASK:

Implement multi-tier rate limiting:

Â  - Anonymous users: 10 requests/hour

Â  - Authenticated free users: 100 requests/hour

Â  - Authenticated paid users: 1000 requests/hour

Â  - Admin users: No limit

  

IMPLEMENTATION:

- Use @hono/rate-limit or custom Redis-based limiter

- Track by: IP address (anonymous) or user ID (authenticated)

- Headers: X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset

- Response: 429 Too Many Requests with retry-after header

  

SPECIAL CASES:

- Burst allowance (allow 20 requests in 1 minute, but 100/hour average)

- Whitelist certain IPs (monitoring systems)

- Different limits for different endpoints (GET /health unlimited)

  

DELIVERABLES:

- Rate limiting middleware: src/middleware/rate-limit.ts

- Configuration in .env (limits per tier)

- User tier detection (from auth token)

- Tests for rate limit enforcement

- Documentation for API consumers

  

**â¸ï¸ YOUR APPROVAL GATE**:

Review rate limits:

â˜ Limits are reasonable (not too strict for legitimate use)

â˜ Different tiers make sense

â˜ Headers inform users of limits

â˜ Has bypass for emergencies (admin override)

**Test**:

  

  

# Test anonymous limit (10/hour)

for i in &#123;1..15&#125;; do

Â  curl http://localhost:3000/chat -d '&#123;"messages":[&#123;"role":"user","content":"test"&#125;]&#125;'

done

# After 10 requests, should get 429

  

# Check headers

curl -I http://localhost:3000/chat

# Should see: X-RateLimit-Remaining: 9

  

# Test with auth token (higher limit)

for i in &#123;1..20&#125;; do

Â  curl http://localhost:3000/chat \

Â  Â  -H "Authorization: Bearer $TOKEN" \

Â  Â  -d '&#123;"messages":[&#123;"role":"user","content":"test"&#125;]&#125;'

done

# Should succeed (authenticated = 100/hour)

  

**âœ… Validation**:

â˜ Rate limiting enforces limits correctly

â˜ Different tiers have different limits

â˜ Headers inform users

â˜ Burst allowance works

**ğŸ“Š Log Cost**: ~$0.08 (25K tokens)

**ğŸ“¦ Step 6.5: Optimize Bundle Size (Frontend)**

**Your Instruction** (in Cursor, open client/package.json):

  

  

Consult the Builder agent.

  

CONTEXT:

Large JavaScript bundles slow page load and hurt user experience.

  

TASK:

Analyze and optimize frontend bundle:

Â  - Run bundle analyzer (webpack-bundle-analyzer or similar)

Â  - Identify large dependencies

Â  - Implement code splitting (lazy load routes)

Â  - Tree-shake unused code

Â  - Use lighter alternatives for heavy libs

  

TARGETS:

- Initial load: &lt;200KB gzipped

- Time to Interactive: &lt;3s on 4G

  

COMMON OPTIMIZATIONS:

- Lazy load dashboard page (only load when navigating)

- Use date-fns instead of moment.js (if used)

- Dynamic imports for chart libraries

- Remove unused CSS (PurgeCSS)

- Compress images

  

DELIVERABLES:

- Bundle analysis report: docs/architecture/bundle-optimization.md

- Optimized webpack/vite config

- Lazy loading for routes

- Before/after Lighthouse scores

  

**â¸ï¸ YOUR APPROVAL GATE**:

Review bundle analysis:

â˜ Identifies biggest contributors (chart lib, etc)

â˜ Proposes reasonable alternatives (not "rewrite everything")

â˜ Code splitting doesn't break functionality

â˜ Images optimized (WebP, compressed)

**Run optimization**:

  

  

cd client

  

# Analyze bundle

npm run build

npm run analyzeÂ  # If configured, or:

npx vite-bundle-visualizer

  

# Check bundle size

ls -lh dist/assets/*.js

# Should be &lt;200KB for main bundle

  

# Run Lighthouse

npx lighthouse http://localhost:5173 --output=json

  

# Compare before/after Performance score

  

**âœ… Validation**:

â˜ Bundle size reduced by 30%+

â˜ Lighthouse Performance score >90

â˜ Time to Interactive &lt;3s

â˜ All features still work

**ğŸ“Š Log Cost**: ~$0.10 (30K tokens)

**âœ… Phase 6 Complete When:**

â˜ Response caching implemented (50%+ hit rate)

â˜ Model routing saving 30-40% costs

â˜ Database queries optimized (&lt;50ms)

â˜ Rate limiting active

â˜ Frontend bundle optimized (&lt;200KB)

â˜ Overall cost reduced by 60-70%

â˜ Latency reduced by 80% for cached requests

â˜ Total cost &lt;$30 for Phase 6

**ğŸ’¡ Key Insight**: Performance = Cost Savings. Fast systems are cheap systems.

**ğŸ‰ MAJOR MILESTONE**: Your system now runs 60-70% cheaper with better performance.

**